carla_server_settings: #carla connection settings.
  ip: '127.0.0.1' #ip to connect 127.0.0.1 if run locally.
  port: 2000 #port to connect default is 2000.
  timeout: 10.0 #time to wait before timeout.

carla_world_settings:
  town: Town10HD #any installed carla town https://carla.readthedocs.io/en/latest/core_map/.
  load_parked_vehicles: True #load or remove parked vehicles (should use _Opt map, Town10HD_Opt, etc.). This can be useful when generating a dataset with object detection annotations since parked vehicles do not provide annotations.
  weather_preset: ClearNoon #Default or any of the predefined Carla weather presets https://carla.readthedocs.io/en/stable/carla_settings/.
  perspective: 1 #perspective of the camera 0 (ego's vehicle hood is not visible), 1 (hood is visible), 2 (will use the specified camera coordinates).
  driving_mode: auto #ad_model (testing a pre-trained model), auto (Carla autopilot), rl_train (training reinforcement learning), rl_eval (evaluating a trained RL model), manual (keyboard arrows or AWSD keys).  
  camera_output: enhanced #enhanced or rgb, if enhanced then the autonomous driving models will utilize the result of the enhancing photorealism enhancement approach.
  skip_frames: 3 #used in synchronous mode to skip a number of ticks. Can be useful to increase performance or generate a synthetic dataset.
  sync_mode: True #run in synchronous or asynchronous mode.
  fixed_delta_seconds: 0.05 #Set a variable time-step.
  no_rendering_mode: False #render or not the UE4 output in the server window. Enable this parameter if you use weather presets that include rain with the Cityscapes pre-trained model.
  spectator_camera_mode: follow #free or follow (if the spectator camera should follow the ego vehicle camera).
  manual_controls: [0.8,0.5,1] #if driving_mode is set to manual define the controls [throttle,steer,brake]. Can be useful depending on the fps and the skip_frames variables.

dataset_settings: #Generating a synthetic Dataset settings.
  export_dataset: False #Generate or not a dataset (available only in synchronous mode).
  dataset_path: G:/ #The path of a disk for the dataset to be saved.
  images_format: png #png or jpg
  capture_when_static: False #Capture frames or not when the vehicle is not moving.
  speed_threshold: 0.1 #Capture frames or not if a vehicle is moving below a speed threshold.
  export_depth: True #Export or not depth buffer frames.
  export_semantic_gt: True #Export or not semantic segmentation ground truth labels.
  export_instance_gt: True
  export_status_json: True #Export or not information about the ego vehicle (steer, throttle, brake, etc.) and world (weather, etc.).
  export_object_annotations: True #Export or not object detection annotations.
  object_visualize_annotations: True #Create or not a cv2 window to visualize the annotations in real-time.
  object_annotations_classes: [12,14,15,16,18,19,13]

other_sensors_settings: #Create or not Lidar,Radar,IMU and GNSS sensors. For their corresponding parameters below refer to https://carla.readthedocs.io/en/latest/ref_sensors/.
  use_lidar: False
  use_radar: False
  use_imu: False
  use_gnss: False

radar_settings:
  transform: [[0,0,2],[0,0,-90]]
  horizontal_fov: 30
  points_per_second: 1500
  range: 100
  vertical_fov: 30

lidar_settings:
  transform: [[0,0,2],[0,0,-90]]
  channels: 32
  range: 10.0
  points_per_second: 56000
  rotation_frequency: 10.0
  upper_fov: 10.0
  horizontal_fov: 360.0
  atmosphere_attenuation_rate: 0.004
  dropoff_general_rate: 0.45
  dropoff_intensity_limit: 0.8
  dropoff_zero_intensity: 0.4
  
ego_vehicle_settings:
  vehicle_model: random  #random or any carla vehicle https://carla.readthedocs.io/en/latest/catalogue_vehicles/.
  camera_location: [5.2,-0.3,1.4] #the camera location will be used only if perspective = 2.
  camera_width: 960 #resolutions that are aligned to 256 for Windows system and CARLA 0.9.14.
  camera_height: 540 #resolutions that are aligned to 256 for Windows system and CARLA 0.9.14.
  camera_fov: 90 #field of view of the camera.
  init_spawn_point: 7 #random or any point id or a transform [[10,10,10],[1,1,1]] ([location,rotation]).

autonomous_driving:
  rl_action_dim: 3 #action space size
  rl_model_name: dqn #model name that is used to save and load checkpoints.
  rl_model_load_episode: 3 #the desired episode of the saved models to be loaded for evaluation.
  rl_num_episodes_save: 1 #save the model per 'rl_num_episodes_save' episodes.
  rl_buffer_max_size: 10000 #max size of the replay memory buffer for previous experiences.
  rl_use_exploration: True #enable or disable exploration-exploitation method.
  ad_brake_threshold: 1.8 #threshold value for the braking to start having an effect. If threshold >= 1 then the vehicle will never brake.
  scenario: default #The scenario that will be loaded from \code\scenarios without the .yaml extension.
  stabilize_num_ticks: 20 #run a number of ticks to stabilize the ego vehicle from the air to the ground when spawning or teleported to another location.
  
general:
  data_type: fp32 #The precision to inference the enhancement model (fp32 or fp16 or tf32 or int8). For TensorRT and Pytorch the recommended is FP16 while ONNX Runtime FP32.
  pygame_output: enhanced #enhanced or rgb or ad_task (for running semantic segmentation or object detection tasks). This parameter defines which result the pygame window will render.
  run_enhanced_model: True #Enable or Disable enhancing photorealism enhancement model (available only if pygame output is set to RGB).
  compiler: pytorch #onnxruntime or tensorrt or pytorch.
  tensorrt_common_path: K:\TensorRT-8.6.1.6\samples\python #the path where the common.py file is located inside TensorRT installation.
  async_data_transfer: False #Transfer the data asynchronously to the GPU. This is available only in asynchronous mode and has high CPU requirements.
  calibration_dataset: K:\code\config\data\val.txt #A small input dataset in txt format (images, buffers, and gt labels paths) to use for calibration when using TensorRT with INT8 data type.
  visualize_buffers: True #Enable or Disable a CV2 window that visualizes G-Buffers. This is just to demonstrate the EPE approach. Disable it to improve the performance.
  
onnx_runtime_settings:
  execution_provider: "CUDAExecutionProvider" #CUDAExecutionProvider or TensorrtExecutionProvider
  enable_fp16: True #this is used when execution_provider is set to TensorrtExecutionProvider. Keep it enabled for fast inference speed.